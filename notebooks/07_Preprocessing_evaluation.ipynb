{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd99070a-2421-4374-9088-549dc9959076",
   "metadata": {},
   "source": [
    "# Preprocessing & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1b787-3bab-4bc1-8b9a-d07c1907635e",
   "metadata": {
    "id": "HS8xYkvIuVZZ"
   },
   "source": [
    "## Preprocessing data (one-hot-encoding, normalization and standardization)\n",
    "\n",
    "A common practice when working with neural networks is to make sure all of the data you pass to them is in the range 0 to 1. \n",
    "This practice is called **normalization** (scaling all values from their original range to, e.g. between 0 and 100,000 to be between 0 and 1).\n",
    "There is another process called **standardization**, which converts all of the data to unit variance and 0 mean.\n",
    "\n",
    "These two practices are often part of a preprocessing pipeline, a series of functions to prepare the data for use with neural networks.\n",
    "\n",
    "Knowing this, some of the major steps you'll take to preprocess your data for a neural network include:\n",
    "* Turning all of your data to numbers (a neural network can't handle strings).\n",
    "* Making sure your data is in the right shape (verifying input and output shapes).\n",
    "* [**Feature scaling**](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler):\n",
    "    * Normalizing data (making sure all values are between 0 and 1). This is done by subtracting the minimum value then dividing by the maximum value minus the minimum. This is also referred to as min-max scaling.\n",
    "    * Standardization (making sure all values have a mean of 0 and a variance of 1). This is done by subtracting the mean value from the target feature and then dividing it by the standard deviation.\n",
    "    * Which one should you use?\n",
    "      * **With neural networks we tend to favour normalization** as they tend to prefer values between 0 and 1 (you'll see this espcially with image processing), however, you'll often find a neural network can perform pretty well with minimal feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a838cf-7402-453f-9252-a5f2c589e4a1",
   "metadata": {},
   "source": [
    "To demeonstrate that, we will use the medical insurance regression example again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f50b1b-9462-4261-a1d5-13dcc0965764",
   "metadata": {
    "id": "9v7P20A2d7H6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 15:23:21.576349: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-04 15:23:21.576420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-04 15:23:21.577214: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-04 15:23:21.583902: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in the insurance dataset\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65f2dbd-bec9-41a2-8a41-e69aaf7de82b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vir8UAIwlUOo",
    "outputId": "e8481873-da05-4f85-a4b9-ec1595ada02a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a glimpse of the data\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b48f9a-33fe-4135-9d09-4d808ce428ea",
   "metadata": {
    "id": "SHMQiNosg3J3"
   },
   "source": [
    "Now, just as before, we need to transform the non-numerical columns into numbers and this time we'll also be normalizing the numerical columns with different ranges (to make sure they're all between 0 and 1).\n",
    "\n",
    "To do this, we're going to use a few classes from Scikit-Learn:\n",
    "* [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) - build a multi-step data preprocessing function for the folllowing transformations:\n",
    "  * [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) - make sure all numerical columns are normalized (between 0 and 1).\n",
    "  * [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) - one hot encode the non-numerical columns.\n",
    "\n",
    "Let's see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2850d62f-9ca3-499a-b6da-6359c89334e1",
   "metadata": {
    "id": "-x9JwbV0hqWh"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6683f013-ed1b-4578-a9e3-1cf3472c4f87",
   "metadata": {
    "id": "-x9JwbV0hqWh"
   },
   "outputs": [],
   "source": [
    "# Create column transformer (this will help us normalize/preprocess our data)\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create X & y\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "# Build our train and test sets (use random state to ensure same split as before)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bee70-7f48-4ee3-a96c-2b2553ca5887",
   "metadata": {
    "id": "Tz58y3nPiBJ-"
   },
   "source": [
    "How does our data look after normalization and one-hot encoding? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe4dfa8-7a19-40bd-9faa-f98edf102796",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VODt2YiziK45",
    "outputId": "58851acc-9ea2-4795-f0b5-f43c609b7bdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-normalized and non-one-hot encoded data example\n",
    "X_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf1a12f-c74b-4699-95bb-9f6785417694",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMYDXdwUnNVt",
    "outputId": "a053ca20-a44f-423e-9795-1d0c66b30633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized and one-hot encoded example\n",
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3cb97-af54-4a42-a42c-25c441409dcb",
   "metadata": {
    "id": "9iI4KtfWib44"
   },
   "source": [
    "How about the shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d0a253-42fe-4d24-8239-9c1f783272c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFmxzqrWntj7",
    "outputId": "0cf4d413-e6eb-4da2-a449-08ef3aefc02f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice the normalized/one-hot encoded shape is larger because of the extra columns\n",
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc994a85-1478-46f5-a9ca-6eedfb70362b",
   "metadata": {
    "id": "MST951aYijTS"
   },
   "source": [
    "Our data is normalized and numerical, let's train a model.\n",
    "\n",
    "We'll use the same model as `insurance_model_2` in the previous NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30129318-9a85-48a0-a257-8a23d2ccdded",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdHnIQqll83Y",
    "outputId": "11ea61c0-8ab5-4ca7-ec68-bde1e94e195d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 15:23:25.700668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43604 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2025-11-04 15:23:26.542800: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f99c9c9ea10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-04 15:23:26.542854: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2025-11-04 15:23:26.548906: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-04 15:23:26.568596: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762266206.665082 1962708 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 2ms/step - loss: 13344.1465 - mae: 13344.1465\n",
      "Epoch 2/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13337.1650 - mae: 13337.1650\n",
      "Epoch 3/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13318.6475 - mae: 13318.6475\n",
      "Epoch 4/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13278.3408 - mae: 13278.3408\n",
      "Epoch 5/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13205.3008 - mae: 13205.3008\n",
      "Epoch 6/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 13088.8809 - mae: 13088.8809\n",
      "Epoch 7/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12918.8545 - mae: 12918.8545\n",
      "Epoch 8/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12684.9639 - mae: 12684.9639\n",
      "Epoch 9/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 12376.9023 - mae: 12376.9023\n",
      "Epoch 10/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11988.7666 - mae: 11988.7666\n",
      "Epoch 11/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11527.2080 - mae: 11527.2080\n",
      "Epoch 12/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11024.0830 - mae: 11024.0830\n",
      "Epoch 13/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10523.0234 - mae: 10523.0234\n",
      "Epoch 14/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10024.6816 - mae: 10024.6816\n",
      "Epoch 15/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 9552.7861 - mae: 9552.7861\n",
      "Epoch 16/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9129.9229 - mae: 9129.9229\n",
      "Epoch 17/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8773.6895 - mae: 8773.6895\n",
      "Epoch 18/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8487.6250 - mae: 8487.6250\n",
      "Epoch 19/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8263.0723 - mae: 8263.0723\n",
      "Epoch 20/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8109.9868 - mae: 8109.9868\n",
      "Epoch 21/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7996.7119 - mae: 7996.7119\n",
      "Epoch 22/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7919.8403 - mae: 7919.8403\n",
      "Epoch 23/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7859.7280 - mae: 7859.7280\n",
      "Epoch 24/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7806.7051 - mae: 7806.7051\n",
      "Epoch 25/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7768.6924 - mae: 7768.6924\n",
      "Epoch 26/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7717.5425 - mae: 7717.5425\n",
      "Epoch 27/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7675.6221 - mae: 7675.6221\n",
      "Epoch 28/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7633.5771 - mae: 7633.5771\n",
      "Epoch 29/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7592.0854 - mae: 7592.0854\n",
      "Epoch 30/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7549.6919 - mae: 7549.6919\n",
      "Epoch 31/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7506.7749 - mae: 7506.7749\n",
      "Epoch 32/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7463.6543 - mae: 7463.6543\n",
      "Epoch 33/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7420.4888 - mae: 7420.4883\n",
      "Epoch 34/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7373.5786 - mae: 7373.5786\n",
      "Epoch 35/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7328.0942 - mae: 7328.0942\n",
      "Epoch 36/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7279.2065 - mae: 7279.2065\n",
      "Epoch 37/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7230.3521 - mae: 7230.3521\n",
      "Epoch 38/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7180.9321 - mae: 7180.9321\n",
      "Epoch 39/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7127.6938 - mae: 7127.6938\n",
      "Epoch 40/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7074.0352 - mae: 7074.0352\n",
      "Epoch 41/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7019.6104 - mae: 7019.6104\n",
      "Epoch 42/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6962.4512 - mae: 6962.4512\n",
      "Epoch 43/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6902.0835 - mae: 6902.0835\n",
      "Epoch 44/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6838.1265 - mae: 6838.1265\n",
      "Epoch 45/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6773.5996 - mae: 6773.5996\n",
      "Epoch 46/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6707.3970 - mae: 6707.3970\n",
      "Epoch 47/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6639.2759 - mae: 6639.2759\n",
      "Epoch 48/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6563.3838 - mae: 6563.3838\n",
      "Epoch 49/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6487.7280 - mae: 6487.7280\n",
      "Epoch 50/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6405.7373 - mae: 6405.7373\n",
      "Epoch 51/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6325.6265 - mae: 6325.6265\n",
      "Epoch 52/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6236.1611 - mae: 6236.1611\n",
      "Epoch 53/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6144.7026 - mae: 6144.7026\n",
      "Epoch 54/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6050.7969 - mae: 6050.7969\n",
      "Epoch 55/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5948.2661 - mae: 5948.2661\n",
      "Epoch 56/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5844.7988 - mae: 5844.7988\n",
      "Epoch 57/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5734.5396 - mae: 5734.5396\n",
      "Epoch 58/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5619.5923 - mae: 5619.5923\n",
      "Epoch 59/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5504.9297 - mae: 5504.9297\n",
      "Epoch 60/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5388.0190 - mae: 5388.0190\n",
      "Epoch 61/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5263.8384 - mae: 5263.8384\n",
      "Epoch 62/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5139.1377 - mae: 5139.1377\n",
      "Epoch 63/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5013.9570 - mae: 5013.9570\n",
      "Epoch 64/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4883.6465 - mae: 4883.6465\n",
      "Epoch 65/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4756.4346 - mae: 4756.4346\n",
      "Epoch 66/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4626.6333 - mae: 4626.6333\n",
      "Epoch 67/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4508.8906 - mae: 4508.8906\n",
      "Epoch 68/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4396.9844 - mae: 4396.9844\n",
      "Epoch 69/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4291.9067 - mae: 4291.9067\n",
      "Epoch 70/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4192.8682 - mae: 4192.8682\n",
      "Epoch 71/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4099.5308 - mae: 4099.5308\n",
      "Epoch 72/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 4014.5332 - mae: 4014.5332\n",
      "Epoch 73/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3939.1982 - mae: 3939.1982\n",
      "Epoch 74/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3874.5552 - mae: 3874.5552\n",
      "Epoch 75/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3824.0486 - mae: 3824.0486\n",
      "Epoch 76/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3782.5552 - mae: 3782.5552\n",
      "Epoch 77/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3748.6653 - mae: 3748.6653\n",
      "Epoch 78/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3724.5732 - mae: 3724.5732\n",
      "Epoch 79/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3705.5149 - mae: 3705.5149\n",
      "Epoch 80/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3692.8069 - mae: 3692.8069\n",
      "Epoch 81/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3683.8599 - mae: 3683.8599\n",
      "Epoch 82/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3678.7705 - mae: 3678.7705\n",
      "Epoch 83/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3671.0081 - mae: 3671.0081\n",
      "Epoch 84/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3667.0635 - mae: 3667.0635\n",
      "Epoch 85/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3664.7175 - mae: 3664.7175\n",
      "Epoch 86/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3661.9712 - mae: 3661.9712\n",
      "Epoch 87/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3658.9045 - mae: 3658.9045\n",
      "Epoch 88/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3656.2324 - mae: 3656.2324\n",
      "Epoch 89/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3654.2090 - mae: 3654.2090\n",
      "Epoch 90/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3652.5349 - mae: 3652.5349\n",
      "Epoch 91/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3649.6797 - mae: 3649.6797\n",
      "Epoch 92/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3648.8711 - mae: 3648.8711\n",
      "Epoch 93/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3646.6638 - mae: 3646.6638\n",
      "Epoch 94/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3645.0657 - mae: 3645.0657\n",
      "Epoch 95/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3645.9858 - mae: 3645.9858\n",
      "Epoch 96/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3643.0264 - mae: 3643.0264\n",
      "Epoch 97/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3640.5540 - mae: 3640.5540\n",
      "Epoch 98/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3638.4946 - mae: 3638.4946\n",
      "Epoch 99/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3637.7402 - mae: 3637.7402\n",
      "Epoch 100/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3636.2961 - mae: 3636.2961\n",
      "Epoch 101/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3633.5635 - mae: 3633.5635\n",
      "Epoch 102/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3631.1021 - mae: 3631.1021\n",
      "Epoch 103/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3629.9805 - mae: 3629.9805\n",
      "Epoch 104/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3627.5693 - mae: 3627.5693\n",
      "Epoch 105/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3625.9521 - mae: 3625.9521\n",
      "Epoch 106/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3624.6667 - mae: 3624.6667\n",
      "Epoch 107/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3624.2764 - mae: 3624.2764\n",
      "Epoch 108/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3621.6724 - mae: 3621.6724\n",
      "Epoch 109/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3622.0571 - mae: 3622.0571\n",
      "Epoch 110/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3618.2915 - mae: 3618.2915\n",
      "Epoch 111/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3615.8806 - mae: 3615.8806\n",
      "Epoch 112/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3613.9597 - mae: 3613.9597\n",
      "Epoch 113/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3612.5132 - mae: 3612.5132\n",
      "Epoch 114/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3611.5281 - mae: 3611.5281\n",
      "Epoch 115/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3609.8354 - mae: 3609.8354\n",
      "Epoch 116/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3608.5784 - mae: 3608.5784\n",
      "Epoch 117/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3605.4595 - mae: 3605.4595\n",
      "Epoch 118/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3601.7185 - mae: 3601.7185\n",
      "Epoch 119/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3603.6575 - mae: 3603.6575\n",
      "Epoch 120/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3601.0356 - mae: 3601.0356\n",
      "Epoch 121/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3596.0078 - mae: 3596.0078\n",
      "Epoch 122/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3595.3320 - mae: 3595.3320\n",
      "Epoch 123/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3593.4634 - mae: 3593.4634\n",
      "Epoch 124/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3591.3169 - mae: 3591.3169\n",
      "Epoch 125/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3589.3635 - mae: 3589.3635\n",
      "Epoch 126/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3588.2156 - mae: 3588.2156\n",
      "Epoch 127/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3588.7480 - mae: 3588.7480\n",
      "Epoch 128/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3585.0542 - mae: 3585.0542\n",
      "Epoch 129/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3583.7427 - mae: 3583.7427\n",
      "Epoch 130/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3580.0203 - mae: 3580.0203\n",
      "Epoch 131/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3578.6711 - mae: 3578.6711\n",
      "Epoch 132/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3575.9321 - mae: 3575.9321\n",
      "Epoch 133/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3574.2864 - mae: 3574.2864\n",
      "Epoch 134/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3572.3364 - mae: 3572.3364\n",
      "Epoch 135/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3570.2998 - mae: 3570.2998\n",
      "Epoch 136/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3568.9551 - mae: 3568.9551\n",
      "Epoch 137/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3567.1387 - mae: 3567.1387\n",
      "Epoch 138/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3564.7793 - mae: 3564.7793\n",
      "Epoch 139/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3564.2383 - mae: 3564.2383\n",
      "Epoch 140/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3561.9543 - mae: 3561.9543\n",
      "Epoch 141/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3562.1729 - mae: 3562.1729\n",
      "Epoch 142/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3559.0132 - mae: 3559.0132\n",
      "Epoch 143/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3558.9675 - mae: 3558.9675\n",
      "Epoch 144/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3556.1709 - mae: 3556.1709\n",
      "Epoch 145/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3554.2700 - mae: 3554.2700\n",
      "Epoch 146/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3554.3992 - mae: 3554.3992\n",
      "Epoch 147/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3551.7922 - mae: 3551.7922\n",
      "Epoch 148/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3550.5527 - mae: 3550.5527\n",
      "Epoch 149/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3547.9380 - mae: 3547.9380\n",
      "Epoch 150/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3547.7207 - mae: 3547.7207\n",
      "Epoch 151/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3546.0786 - mae: 3546.0786\n",
      "Epoch 152/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3544.2703 - mae: 3544.2703\n",
      "Epoch 153/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3542.9443 - mae: 3542.9443\n",
      "Epoch 154/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3544.2146 - mae: 3544.2146\n",
      "Epoch 155/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3541.6753 - mae: 3541.6753\n",
      "Epoch 156/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3540.1970 - mae: 3540.1970\n",
      "Epoch 157/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3538.5347 - mae: 3538.5347\n",
      "Epoch 158/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3535.6460 - mae: 3535.6460\n",
      "Epoch 159/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3534.1270 - mae: 3534.1270\n",
      "Epoch 160/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3533.8247 - mae: 3533.8247\n",
      "Epoch 161/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3530.7778 - mae: 3530.7778\n",
      "Epoch 162/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3530.2695 - mae: 3530.2695\n",
      "Epoch 163/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3528.7764 - mae: 3528.7764\n",
      "Epoch 164/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3527.4285 - mae: 3527.4285\n",
      "Epoch 165/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3525.4670 - mae: 3525.4670\n",
      "Epoch 166/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3523.8721 - mae: 3523.8721\n",
      "Epoch 167/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3522.7996 - mae: 3522.7996\n",
      "Epoch 168/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3521.6753 - mae: 3521.6753\n",
      "Epoch 169/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3520.6611 - mae: 3520.6611\n",
      "Epoch 170/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3518.9531 - mae: 3518.9531\n",
      "Epoch 171/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3518.6165 - mae: 3518.6165\n",
      "Epoch 172/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3517.3994 - mae: 3517.3994\n",
      "Epoch 173/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3515.7634 - mae: 3515.7634\n",
      "Epoch 174/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3514.6565 - mae: 3514.6565\n",
      "Epoch 175/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3513.3127 - mae: 3513.3127\n",
      "Epoch 176/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3513.3032 - mae: 3513.3032\n",
      "Epoch 177/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3513.5854 - mae: 3513.5854\n",
      "Epoch 178/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3511.2292 - mae: 3511.2292\n",
      "Epoch 179/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3513.3335 - mae: 3513.3335\n",
      "Epoch 180/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3508.2646 - mae: 3508.2646\n",
      "Epoch 181/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3506.1528 - mae: 3506.1528\n",
      "Epoch 182/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3505.5002 - mae: 3505.5002\n",
      "Epoch 183/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3503.6760 - mae: 3503.6760\n",
      "Epoch 184/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3503.0049 - mae: 3503.0049\n",
      "Epoch 185/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3502.7095 - mae: 3502.7095\n",
      "Epoch 186/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3500.0710 - mae: 3500.0710\n",
      "Epoch 187/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3500.6509 - mae: 3500.6509\n",
      "Epoch 188/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3497.7302 - mae: 3497.7302\n",
      "Epoch 189/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3496.0740 - mae: 3496.0740\n",
      "Epoch 190/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3498.0393 - mae: 3498.0393\n",
      "Epoch 191/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3503.1521 - mae: 3503.1521\n",
      "Epoch 192/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3493.1174 - mae: 3493.1174\n",
      "Epoch 193/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3492.8420 - mae: 3492.8420\n",
      "Epoch 194/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3490.2549 - mae: 3490.2549\n",
      "Epoch 195/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3490.0481 - mae: 3490.0481\n",
      "Epoch 196/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3490.7759 - mae: 3490.7759\n",
      "Epoch 197/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3487.1121 - mae: 3487.1121\n",
      "Epoch 198/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3486.0151 - mae: 3486.0151\n",
      "Epoch 199/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3484.8271 - mae: 3484.8271\n",
      "Epoch 200/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3485.2791 - mae: 3485.2791\n",
      "Epoch 201/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3481.4421 - mae: 3481.4421\n",
      "Epoch 202/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3481.3215 - mae: 3481.3215\n",
      "Epoch 203/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3478.7402 - mae: 3478.7402\n",
      "Epoch 204/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3479.8787 - mae: 3479.8787\n",
      "Epoch 205/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3476.4265 - mae: 3476.4265\n",
      "Epoch 206/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3475.8362 - mae: 3475.8362\n",
      "Epoch 207/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3475.6609 - mae: 3475.6609\n",
      "Epoch 208/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.8357 - mae: 3474.8357\n",
      "Epoch 209/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.1475 - mae: 3474.1475\n",
      "Epoch 210/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.0393 - mae: 3474.0393\n",
      "Epoch 211/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.1951 - mae: 3473.1951\n",
      "Epoch 212/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.1123 - mae: 3473.1123\n",
      "Epoch 213/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.5435 - mae: 3472.5435\n",
      "Epoch 214/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.7471 - mae: 3474.7471\n",
      "Epoch 215/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.6113 - mae: 3473.6113\n",
      "Epoch 216/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.4543 - mae: 3472.4543\n",
      "Epoch 217/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.8552 - mae: 3474.8552\n",
      "Epoch 218/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.2678 - mae: 3472.2678\n",
      "Epoch 219/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.7971 - mae: 3472.7971\n",
      "Epoch 220/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3471.7275 - mae: 3471.7275\n",
      "Epoch 221/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.1926 - mae: 3474.1926\n",
      "Epoch 222/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.7625 - mae: 3473.7625\n",
      "Epoch 223/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.7839 - mae: 3472.7839\n",
      "Epoch 224/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.2498 - mae: 3473.2498\n",
      "Epoch 225/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.9744 - mae: 3472.9744\n",
      "Epoch 226/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.8145 - mae: 3471.8145\n",
      "Epoch 227/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.3147 - mae: 3471.3147\n",
      "Epoch 228/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.3716 - mae: 3473.3716\n",
      "Epoch 229/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.1873 - mae: 3472.1873\n",
      "Epoch 230/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.4116 - mae: 3474.4116\n",
      "Epoch 231/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3471.8352 - mae: 3471.8352\n",
      "Epoch 232/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.6865 - mae: 3472.6865\n",
      "Epoch 233/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.1663 - mae: 3472.1663\n",
      "Epoch 234/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.6345 - mae: 3472.6345\n",
      "Epoch 235/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.1902 - mae: 3474.1902\n",
      "Epoch 236/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.4307 - mae: 3473.4307\n",
      "Epoch 237/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.9761 - mae: 3472.9761\n",
      "Epoch 238/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.7031 - mae: 3473.7031\n",
      "Epoch 239/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.6702 - mae: 3474.6702\n",
      "Epoch 240/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.5222 - mae: 3472.5222\n",
      "Epoch 241/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.7361 - mae: 3471.7361\n",
      "Epoch 242/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.9321 - mae: 3473.9321\n",
      "Epoch 243/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.0352 - mae: 3472.0352\n",
      "Epoch 244/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.7075 - mae: 3473.7075\n",
      "Epoch 245/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.0708 - mae: 3472.0708\n",
      "Epoch 246/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.4294 - mae: 3473.4294\n",
      "Epoch 247/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.5049 - mae: 3472.5049\n",
      "Epoch 248/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.0444 - mae: 3474.0444\n",
      "Epoch 249/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.8220 - mae: 3474.8220\n",
      "Epoch 250/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.1895 - mae: 3472.1895\n",
      "Epoch 251/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.3774 - mae: 3471.3774\n",
      "Epoch 252/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.3711 - mae: 3473.3711\n",
      "Epoch 253/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.8406 - mae: 3472.8406\n",
      "Epoch 254/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.8171 - mae: 3471.8171\n",
      "Epoch 255/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.7268 - mae: 3472.7268\n",
      "Epoch 256/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.9333 - mae: 3474.9333\n",
      "Epoch 257/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3475.8723 - mae: 3475.8723\n",
      "Epoch 258/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.1709 - mae: 3472.1709\n",
      "Epoch 259/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.2175 - mae: 3474.2175\n",
      "Epoch 260/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.9917 - mae: 3471.9917\n",
      "Epoch 261/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.8809 - mae: 3472.8809\n",
      "Epoch 262/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.7869 - mae: 3472.7869\n",
      "Epoch 263/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.5815 - mae: 3472.5815\n",
      "Epoch 264/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.4192 - mae: 3472.4192\n",
      "Epoch 265/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.8582 - mae: 3472.8582\n",
      "Epoch 266/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.5032 - mae: 3472.5032\n",
      "Epoch 267/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.5793 - mae: 3473.5793\n",
      "Epoch 268/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.8643 - mae: 3471.8643\n",
      "Epoch 269/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3471.8613 - mae: 3471.8613\n",
      "Epoch 270/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3471.9575 - mae: 3471.9575\n",
      "Epoch 271/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.2520 - mae: 3472.2520\n",
      "Epoch 272/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.9878 - mae: 3471.9878\n",
      "Epoch 273/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.5588 - mae: 3472.5588\n",
      "Epoch 274/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.2185 - mae: 3472.2185\n",
      "Epoch 275/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.8574 - mae: 3473.8574\n",
      "Epoch 276/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.3630 - mae: 3473.3630\n",
      "Epoch 277/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3471.9700 - mae: 3471.9700\n",
      "Epoch 278/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.0215 - mae: 3472.0215\n",
      "Epoch 279/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3476.1968 - mae: 3476.1968\n",
      "Epoch 280/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.2776 - mae: 3472.2776\n",
      "Epoch 281/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.2729 - mae: 3472.2729\n",
      "Epoch 282/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.0559 - mae: 3472.0559\n",
      "Epoch 283/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.9297 - mae: 3472.9297\n",
      "Epoch 284/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.4214 - mae: 3472.4214\n",
      "Epoch 285/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.8750 - mae: 3471.8750\n",
      "Epoch 286/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.1887 - mae: 3472.1887\n",
      "Epoch 287/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.6182 - mae: 3472.6182\n",
      "Epoch 288/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3472.1599 - mae: 3472.1599\n",
      "Epoch 289/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.8840 - mae: 3473.8840\n",
      "Epoch 290/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.0828 - mae: 3473.0828\n",
      "Epoch 291/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.3269 - mae: 3471.3269\n",
      "Epoch 292/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.6987 - mae: 3473.6987\n",
      "Epoch 293/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3471.8486 - mae: 3471.8486\n",
      "Epoch 294/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.2351 - mae: 3473.2351\n",
      "Epoch 295/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3473.1592 - mae: 3473.1592\n",
      "Epoch 296/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.2361 - mae: 3474.2361\n",
      "Epoch 297/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3475.9377 - mae: 3475.9377\n",
      "Epoch 298/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3474.9441 - mae: 3474.9441\n",
      "Epoch 299/300\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3471.8669 - mae: 3471.8669\n",
      "Epoch 300/300\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.9126 - mae: 3472.9126\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build the model (3 layers, 100, 10, 1 units)\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])\n",
    "\n",
    "# Fit the model for 200 epochs (same as insurance_model_2)\n",
    "history = insurance_model_3.fit(X_train_normal, y_train, epochs=300, verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b2ea14-ac30-427e-925e-aa5d79f2e4d6",
   "metadata": {
    "id": "-DjwktO6jW41"
   },
   "source": [
    "Let's evaluate the model on the normalized test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e04e1b2-abad-420b-bbcc-ac8255e3d845",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBcXZu9AnZfP",
    "outputId": "383dfb1a-ef18-4ad7-c696-41453afb729f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 3161.1619 - mae: 3161.1619\n"
     ]
    }
   ],
   "source": [
    "# Evaulate 3rd model\n",
    "insurance_model_3_loss, insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ea435-8e85-4ec9-a238-bc5f77b55292",
   "metadata": {
    "id": "ZlHro290jhtX"
   },
   "source": [
    "And finally, let's compare the results from `insurance_model_2` (trained on non-normalized data) and `insurance_model_3` (trained on normalized data). For that, we will load the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c256c089-62e8-4e99-b61a-f95b69ea0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_model_2 = tf.keras.models.load_model('./insurance_model_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30189f5-822e-4825-ab9b-ce69e7805435",
   "metadata": {},
   "source": [
    "We need to (only) one-hot encode our data for the `insurance_model_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b472f6a-a4ba-4550-ae6a-fe134943b2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct_one_hot = make_column_transformer(\n",
    "    (SimpleImputer(), [\"age\",\"bmi\",\"children\"]),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])) # remainder makes sure the numeric columns do't get dropped\n",
    "\n",
    "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
    "ct_one_hot.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
    "X_train_one_hot = ct_one_hot.transform(X_train)\n",
    "X_test_one_hot = ct_one_hot.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dccbbdcd-9667-43d0-ab7c-55720752583b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45.   , 25.175,  2.   , ...,  0.   ,  0.   ,  0.   ],\n",
       "       [36.   , 30.02 ,  0.   , ...,  1.   ,  0.   ,  0.   ],\n",
       "       [64.   , 26.885,  0.   , ...,  1.   ,  0.   ,  0.   ],\n",
       "       ...,\n",
       "       [38.   , 28.025,  1.   , ...,  0.   ,  0.   ,  0.   ],\n",
       "       [54.   , 47.41 ,  0.   , ...,  0.   ,  1.   ,  0.   ],\n",
       "       [51.   , 34.2  ,  1.   , ...,  0.   ,  0.   ,  1.   ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb49ab5d-dc14-438e-b877-c4b7dd15795a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 3223.4307 - mae: 3223.4307\n"
     ]
    }
   ],
   "source": [
    "insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test_one_hot, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a31b4011-4aee-4dc0-9626-76b89a525b62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybZtnVlNjCJO",
    "outputId": "d4713c7f-d84e-4a9f-f1b8-a97f9a457e16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3223.4306640625, 3161.161865234375)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare modelling results from non-normalized data and normalized data\n",
    "insurance_model_2_mae, insurance_model_3_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a91369-8a2c-4dc5-82e7-36d8d4458462",
   "metadata": {
    "id": "gUttViY4jzi8"
   },
   "source": [
    "From this we can see normalizing the data results in a smaller error using the same model than not normalizing the data.\n",
    "One of the main benefits of normalization, however,  is faster convergence time.\n",
    "`insurance_model_2` may have eventually achieved the same results as `insurance_model_3` if we left it training for longer. \n",
    "Obviously, the results may change if we were to alter the architectures of the models, e.g. more hidden units per layer or more layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f85950-3a8b-4875-a93e-6b3bcc1f3bf0",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\"Callbacks can be passed to keras methods such as fit, evaluate, and predict in order to hook into the various stages of the model training and inference lifecycle.\" Source: TensorFlow documentation.\n",
    "\n",
    "There are many different callbacks you can set. In fact, you can also create your custom callbacks.\n",
    "I would like to point out just two very useful callbacks here: [**early stopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), and [**TensorBoard**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard). We could (or should) pass all the callbacks in one [callbacks list](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/CallbackList). However, to better demonstrate what each callback does, I will go through them seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a670666-793e-4529-9ef7-4fe6ae53f831",
   "metadata": {},
   "source": [
    "### Early stopping callback\n",
    "It is often hard to tell for how many epochs you should let your models train, without risking under- or overfitting. In this situation the early stopping callback comes in handy.\n",
    "It simply stops the training, as soon as a predefined metric is no longer improving. You can decide what the tolarance should be to define \"no longer improving\" by passing `min_delta`, and how many epochs the callback should wait before interrupting the training by passing the `patience` argument.\n",
    "\n",
    "Let's have a look how it works on our last model. We will set the number of epochs to 500 to provoke early stopping.\n",
    "For some reason, which is not quite obvious, we have to build and compile model_3 again as model_4 to make the callback work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48cf04c2-28b8-444b-b744-8f6ca8f8e4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5) # Training will stock, if there is no improvement on the loss after 5 consecutive epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1861e362-adb8-48bf-8b8c-ddfad621e8c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdHnIQqll83Y",
    "outputId": "11ea61c0-8ab5-4ca7-ec68-bde1e94e195d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build the model (3 layers, 100, 10, 1 units)\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "668b3dc0-c9ca-489e-8081-b020e582e653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 1s 5ms/step - loss: 13344.3848 - mae: 13344.3848 - val_loss: 12963.9102 - val_mae: 12963.9102\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13337.1318 - mae: 13337.1318 - val_loss: 12952.2607 - val_mae: 12952.2607\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13318.2988 - mae: 13318.2988 - val_loss: 12923.5605 - val_mae: 12923.5605\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13276.6309 - mae: 13276.6309 - val_loss: 12865.6787 - val_mae: 12865.6787\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13200.1406 - mae: 13200.1406 - val_loss: 12767.0801 - val_mae: 12767.0801\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13077.8203 - mae: 13077.8203 - val_loss: 12617.5117 - val_mae: 12617.5117\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12899.3320 - mae: 12899.3320 - val_loss: 12406.3916 - val_mae: 12406.3916\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12654.6094 - mae: 12654.6094 - val_loss: 12123.6621 - val_mae: 12123.6621\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12333.4932 - mae: 12333.4932 - val_loss: 11760.7129 - val_mae: 11760.7129\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11931.3867 - mae: 11931.3867 - val_loss: 11318.3545 - val_mae: 11318.3545\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11457.4688 - mae: 11457.4688 - val_loss: 10825.3643 - val_mae: 10825.3643\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10951.0381 - mae: 10951.0381 - val_loss: 10336.0146 - val_mae: 10336.0146\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10448.4443 - mae: 10448.4443 - val_loss: 9851.6982 - val_mae: 9851.6982\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9952.5039 - mae: 9952.5039 - val_loss: 9403.9014 - val_mae: 9403.9014\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9484.6416 - mae: 9484.6416 - val_loss: 9024.5400 - val_mae: 9024.5400\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9067.7939 - mae: 9067.7939 - val_loss: 8736.0264 - val_mae: 8736.0264\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8722.7920 - mae: 8722.7920 - val_loss: 8524.0117 - val_mae: 8524.0117\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8442.6523 - mae: 8442.6523 - val_loss: 8370.2246 - val_mae: 8370.2246\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8232.4199 - mae: 8232.4199 - val_loss: 8267.3613 - val_mae: 8267.3613\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8087.2056 - mae: 8087.2056 - val_loss: 8195.7021 - val_mae: 8195.7021\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7979.1030 - mae: 7979.1030 - val_loss: 8146.1270 - val_mae: 8146.1270\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7905.1143 - mae: 7905.1143 - val_loss: 8100.6733 - val_mae: 8100.6733\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7846.9131 - mae: 7846.9131 - val_loss: 8060.8994 - val_mae: 8060.8994\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7794.0708 - mae: 7794.0708 - val_loss: 8022.6177 - val_mae: 8022.6177\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7755.0522 - mae: 7755.0522 - val_loss: 7986.7642 - val_mae: 7986.7642\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7703.1660 - mae: 7703.1660 - val_loss: 7945.3657 - val_mae: 7945.3657\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7660.7944 - mae: 7660.7944 - val_loss: 7905.5430 - val_mae: 7905.5430\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7618.1704 - mae: 7618.1704 - val_loss: 7863.3218 - val_mae: 7863.3218\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7575.4668 - mae: 7575.4668 - val_loss: 7820.0054 - val_mae: 7820.0054\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7531.8105 - mae: 7531.8105 - val_loss: 7780.6226 - val_mae: 7780.6226\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7487.6797 - mae: 7487.6797 - val_loss: 7733.8667 - val_mae: 7733.8667\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7443.3652 - mae: 7443.3652 - val_loss: 7690.9043 - val_mae: 7690.9043\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7399.0161 - mae: 7399.0161 - val_loss: 7639.8940 - val_mae: 7639.8940\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7350.6172 - mae: 7350.6172 - val_loss: 7595.6855 - val_mae: 7595.6855\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7303.6030 - mae: 7303.6030 - val_loss: 7552.9619 - val_mae: 7552.9619\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7253.3247 - mae: 7253.3247 - val_loss: 7500.6782 - val_mae: 7500.6782\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7202.9233 - mae: 7202.9233 - val_loss: 7447.6895 - val_mae: 7447.6895\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7151.6621 - mae: 7151.6621 - val_loss: 7396.1157 - val_mae: 7396.1157\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7096.4912 - mae: 7096.4912 - val_loss: 7335.9727 - val_mae: 7335.9727\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7040.9214 - mae: 7040.9214 - val_loss: 7279.7109 - val_mae: 7279.7109\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6984.2373 - mae: 6984.2373 - val_loss: 7219.4009 - val_mae: 7219.4009\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6924.5566 - mae: 6924.5566 - val_loss: 7155.8384 - val_mae: 7155.8384\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6861.7798 - mae: 6861.7798 - val_loss: 7097.1436 - val_mae: 7097.1436\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6795.1816 - mae: 6795.1816 - val_loss: 7025.8457 - val_mae: 7025.8457\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6727.6128 - mae: 6727.6128 - val_loss: 6958.2134 - val_mae: 6958.2134\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6658.2983 - mae: 6658.2983 - val_loss: 6881.8311 - val_mae: 6881.8311\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6586.5938 - mae: 6586.5938 - val_loss: 6809.8115 - val_mae: 6809.8115\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6507.2666 - mae: 6507.2666 - val_loss: 6720.5640 - val_mae: 6720.5640\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6427.8872 - mae: 6427.8872 - val_loss: 6638.8506 - val_mae: 6638.8506\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6341.4600 - mae: 6341.4600 - val_loss: 6545.9126 - val_mae: 6545.9126\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6256.5547 - mae: 6256.5547 - val_loss: 6451.6025 - val_mae: 6451.6025\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6162.6714 - mae: 6162.6714 - val_loss: 6347.0415 - val_mae: 6347.0415\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6065.9800 - mae: 6065.9800 - val_loss: 6244.0483 - val_mae: 6244.0483\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5966.8188 - mae: 5966.8188 - val_loss: 6133.7427 - val_mae: 6133.7427\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5858.8843 - mae: 5858.8843 - val_loss: 6013.3335 - val_mae: 6013.3335\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5749.8193 - mae: 5749.8193 - val_loss: 5891.9609 - val_mae: 5891.9609\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5633.8774 - mae: 5633.8774 - val_loss: 5761.8086 - val_mae: 5761.8086\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5516.6240 - mae: 5516.6240 - val_loss: 5625.0044 - val_mae: 5625.0044\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5397.6304 - mae: 5397.6304 - val_loss: 5482.6738 - val_mae: 5482.6738\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5274.2588 - mae: 5274.2588 - val_loss: 5334.2393 - val_mae: 5334.2393\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5147.8555 - mae: 5147.8555 - val_loss: 5177.8174 - val_mae: 5177.8174\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5017.8555 - mae: 5017.8555 - val_loss: 5022.4443 - val_mae: 5022.4443\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4889.4082 - mae: 4889.4082 - val_loss: 4864.4819 - val_mae: 4864.4819\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4756.9204 - mae: 4756.9204 - val_loss: 4713.9844 - val_mae: 4713.9844\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4630.9653 - mae: 4630.9653 - val_loss: 4555.0254 - val_mae: 4555.0254\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4508.4087 - mae: 4508.4087 - val_loss: 4416.2568 - val_mae: 4416.2568\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4401.1934 - mae: 4401.1934 - val_loss: 4276.5332 - val_mae: 4276.5332\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4295.5737 - mae: 4295.5737 - val_loss: 4153.4321 - val_mae: 4153.4321\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4195.0806 - mae: 4195.0806 - val_loss: 4040.7424 - val_mae: 4040.7424\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4102.6470 - mae: 4102.6470 - val_loss: 3937.6277 - val_mae: 3937.6277\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4016.4463 - mae: 4016.4463 - val_loss: 3850.6848 - val_mae: 3850.6848\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3941.9646 - mae: 3941.9646 - val_loss: 3768.7649 - val_mae: 3768.7649\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3878.1960 - mae: 3878.1960 - val_loss: 3702.0327 - val_mae: 3702.0327\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3824.7703 - mae: 3824.7703 - val_loss: 3644.9973 - val_mae: 3644.9973\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3783.1509 - mae: 3783.1509 - val_loss: 3601.8125 - val_mae: 3601.8125\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3751.2478 - mae: 3751.2478 - val_loss: 3571.3726 - val_mae: 3571.3726\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3725.2300 - mae: 3725.2300 - val_loss: 3546.5867 - val_mae: 3546.5867\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3706.7056 - mae: 3706.7056 - val_loss: 3532.2710 - val_mae: 3532.2710\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3693.4836 - mae: 3693.4836 - val_loss: 3520.5293 - val_mae: 3520.5293\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3684.1245 - mae: 3684.1245 - val_loss: 3511.7468 - val_mae: 3511.7468\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3677.0430 - mae: 3677.0430 - val_loss: 3503.8862 - val_mae: 3503.8862\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3673.1309 - mae: 3673.1309 - val_loss: 3500.1292 - val_mae: 3500.1292\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3666.6714 - mae: 3666.6714 - val_loss: 3494.3445 - val_mae: 3494.3445\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3663.9932 - mae: 3663.9932 - val_loss: 3489.8083 - val_mae: 3489.8083\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3661.6038 - mae: 3661.6038 - val_loss: 3489.8008 - val_mae: 3489.8008\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3659.4326 - mae: 3659.4326 - val_loss: 3483.1238 - val_mae: 3483.1238\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3656.5127 - mae: 3656.5127 - val_loss: 3478.2986 - val_mae: 3478.2986\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3653.8262 - mae: 3653.8262 - val_loss: 3474.8792 - val_mae: 3474.8792\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3652.1931 - mae: 3652.1931 - val_loss: 3470.8894 - val_mae: 3470.8894\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3650.7000 - mae: 3650.7000 - val_loss: 3468.2161 - val_mae: 3468.2161\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3647.4868 - mae: 3647.4868 - val_loss: 3463.9863 - val_mae: 3463.9863\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3646.7883 - mae: 3646.7883 - val_loss: 3461.5449 - val_mae: 3461.5449\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3644.4526 - mae: 3644.4526 - val_loss: 3458.8062 - val_mae: 3458.8062\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3642.8306 - mae: 3642.8306 - val_loss: 3454.0830 - val_mae: 3454.0830\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3644.0630 - mae: 3644.0630 - val_loss: 3452.9346 - val_mae: 3452.9346\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3640.4336 - mae: 3640.4336 - val_loss: 3447.5322 - val_mae: 3447.5322\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3638.3577 - mae: 3638.3577 - val_loss: 3446.5276 - val_mae: 3446.5276\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3636.2515 - mae: 3636.2515 - val_loss: 3445.1719 - val_mae: 3445.1719\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3635.5437 - mae: 3635.5437 - val_loss: 3440.2812 - val_mae: 3440.2812\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3633.9592 - mae: 3633.9592 - val_loss: 3436.4324 - val_mae: 3436.4324\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3631.2476 - mae: 3631.2476 - val_loss: 3433.6541 - val_mae: 3433.6541\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3628.6667 - mae: 3628.6667 - val_loss: 3434.0405 - val_mae: 3434.0405\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3627.5618 - mae: 3627.5618 - val_loss: 3429.4683 - val_mae: 3429.4683\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3625.1882 - mae: 3625.1882 - val_loss: 3427.7517 - val_mae: 3427.7517\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3623.5176 - mae: 3623.5176 - val_loss: 3424.0146 - val_mae: 3424.0146\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3622.1262 - mae: 3622.1262 - val_loss: 3419.2463 - val_mae: 3419.2463\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3621.5801 - mae: 3621.5801 - val_loss: 3419.2239 - val_mae: 3419.2239\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3619.3113 - mae: 3619.3113 - val_loss: 3413.9268 - val_mae: 3413.9268\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3619.8638 - mae: 3619.8638 - val_loss: 3414.7788 - val_mae: 3414.7788\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3615.7412 - mae: 3615.7412 - val_loss: 3406.9297 - val_mae: 3406.9297\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3613.0562 - mae: 3613.0562 - val_loss: 3406.9368 - val_mae: 3406.9368\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3611.0840 - mae: 3611.0840 - val_loss: 3402.0071 - val_mae: 3402.0071\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3609.6855 - mae: 3609.6855 - val_loss: 3401.9087 - val_mae: 3401.9087\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3608.8228 - mae: 3608.8228 - val_loss: 3398.3311 - val_mae: 3398.3311\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3606.9692 - mae: 3606.9692 - val_loss: 3396.0269 - val_mae: 3396.0269\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3605.7432 - mae: 3605.7432 - val_loss: 3393.9736 - val_mae: 3393.9736\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3602.5295 - mae: 3602.5295 - val_loss: 3390.4548 - val_mae: 3390.4548\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3598.7034 - mae: 3598.7034 - val_loss: 3386.1951 - val_mae: 3386.1951\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3600.6963 - mae: 3600.6963 - val_loss: 3382.5269 - val_mae: 3382.5269\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3598.0334 - mae: 3598.0334 - val_loss: 3378.2239 - val_mae: 3378.2239\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3592.9041 - mae: 3592.9041 - val_loss: 3378.5605 - val_mae: 3378.5605\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3592.2590 - mae: 3592.2590 - val_loss: 3372.8706 - val_mae: 3372.8706\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3590.2603 - mae: 3590.2603 - val_loss: 3370.4558 - val_mae: 3370.4558\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3587.9246 - mae: 3587.9246 - val_loss: 3367.2986 - val_mae: 3367.2986\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3585.9011 - mae: 3585.9011 - val_loss: 3363.4775 - val_mae: 3363.4775\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3585.0601 - mae: 3585.0601 - val_loss: 3360.7151 - val_mae: 3360.7151\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3585.2449 - mae: 3585.2449 - val_loss: 3360.3813 - val_mae: 3360.3813\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3581.7410 - mae: 3581.7410 - val_loss: 3356.5107 - val_mae: 3356.5107\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3580.3022 - mae: 3580.3022 - val_loss: 3351.2349 - val_mae: 3351.2349\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3576.5991 - mae: 3576.5991 - val_loss: 3348.5308 - val_mae: 3348.5308\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3575.3628 - mae: 3575.3628 - val_loss: 3343.1333 - val_mae: 3343.1333\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3572.3171 - mae: 3572.3171 - val_loss: 3341.8643 - val_mae: 3341.8643\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3570.9968 - mae: 3570.9968 - val_loss: 3339.5142 - val_mae: 3339.5142\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3568.6824 - mae: 3568.6824 - val_loss: 3336.0051 - val_mae: 3336.0051\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3566.7690 - mae: 3566.7690 - val_loss: 3332.7092 - val_mae: 3332.7092\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3565.1726 - mae: 3565.1726 - val_loss: 3328.5115 - val_mae: 3328.5115\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3563.8901 - mae: 3563.8901 - val_loss: 3326.3628 - val_mae: 3326.3628\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3561.5530 - mae: 3561.5530 - val_loss: 3325.6318 - val_mae: 3325.6318\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3560.8799 - mae: 3560.8799 - val_loss: 3321.3950 - val_mae: 3321.3950\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3558.7283 - mae: 3558.7283 - val_loss: 3318.3521 - val_mae: 3318.3521\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3558.6965 - mae: 3558.6965 - val_loss: 3315.1106 - val_mae: 3315.1106\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3555.8445 - mae: 3555.8445 - val_loss: 3313.5957 - val_mae: 3313.5957\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3556.2417 - mae: 3556.2417 - val_loss: 3311.2820 - val_mae: 3311.2820\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3553.2266 - mae: 3553.2266 - val_loss: 3306.5747 - val_mae: 3306.5747\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3551.2075 - mae: 3551.2075 - val_loss: 3301.8315 - val_mae: 3301.8315\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3551.5083 - mae: 3551.5083 - val_loss: 3301.4031 - val_mae: 3301.4031\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3548.7988 - mae: 3548.7988 - val_loss: 3297.6621 - val_mae: 3297.6621\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3547.5195 - mae: 3547.5195 - val_loss: 3294.4014 - val_mae: 3294.4014\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3544.7905 - mae: 3544.7905 - val_loss: 3290.2161 - val_mae: 3290.2161\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3544.3254 - mae: 3544.3254 - val_loss: 3286.9592 - val_mae: 3286.9592\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3542.7122 - mae: 3542.7122 - val_loss: 3283.5847 - val_mae: 3283.5847\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3541.2556 - mae: 3541.2556 - val_loss: 3279.5269 - val_mae: 3279.5269\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3539.6052 - mae: 3539.6052 - val_loss: 3280.2085 - val_mae: 3280.2085\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3541.0588 - mae: 3541.0588 - val_loss: 3277.0078 - val_mae: 3277.0078\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3538.5754 - mae: 3538.5754 - val_loss: 3274.8179 - val_mae: 3274.8179\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3536.7827 - mae: 3536.7827 - val_loss: 3272.1821 - val_mae: 3272.1821\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3535.2964 - mae: 3535.2964 - val_loss: 3267.6521 - val_mae: 3267.6521\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3532.2104 - mae: 3532.2104 - val_loss: 3266.6301 - val_mae: 3266.6301\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3530.7427 - mae: 3530.7427 - val_loss: 3261.3972 - val_mae: 3261.3972\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3530.4221 - mae: 3530.4221 - val_loss: 3258.6956 - val_mae: 3258.6956\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3527.3701 - mae: 3527.3701 - val_loss: 3255.0962 - val_mae: 3255.0962\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3526.7524 - mae: 3526.7524 - val_loss: 3251.3674 - val_mae: 3251.3674\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3524.8706 - mae: 3524.8706 - val_loss: 3248.6646 - val_mae: 3248.6646\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3524.4807 - mae: 3524.4807 - val_loss: 3246.5986 - val_mae: 3246.5986\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3522.4741 - mae: 3522.4741 - val_loss: 3243.4204 - val_mae: 3243.4204\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3520.8855 - mae: 3520.8855 - val_loss: 3239.7722 - val_mae: 3239.7722\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3519.9446 - mae: 3519.9446 - val_loss: 3235.1924 - val_mae: 3235.1924\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3518.6133 - mae: 3518.6133 - val_loss: 3238.5530 - val_mae: 3238.5530\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3517.3591 - mae: 3517.3591 - val_loss: 3234.6001 - val_mae: 3234.6001\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3516.0142 - mae: 3516.0142 - val_loss: 3232.5312 - val_mae: 3232.5312\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3515.3628 - mae: 3515.3628 - val_loss: 3228.6245 - val_mae: 3228.6245\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3513.8347 - mae: 3513.8347 - val_loss: 3226.6851 - val_mae: 3226.6851\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3512.6235 - mae: 3512.6235 - val_loss: 3222.2732 - val_mae: 3222.2732\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3511.5310 - mae: 3511.5310 - val_loss: 3224.9326 - val_mae: 3224.9326\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3510.1389 - mae: 3510.1389 - val_loss: 3222.5391 - val_mae: 3222.5391\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3510.0935 - mae: 3510.0935 - val_loss: 3218.9612 - val_mae: 3218.9612\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3510.4773 - mae: 3510.4773 - val_loss: 3215.4834 - val_mae: 3215.4834\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3508.0212 - mae: 3508.0212 - val_loss: 3216.3613 - val_mae: 3216.3613\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3509.9751 - mae: 3509.9751 - val_loss: 3215.2063 - val_mae: 3215.2063\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3504.8726 - mae: 3504.8726 - val_loss: 3209.2583 - val_mae: 3209.2583\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3502.8523 - mae: 3502.8523 - val_loss: 3211.6130 - val_mae: 3211.6130\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3502.1943 - mae: 3502.1943 - val_loss: 3206.6338 - val_mae: 3206.6338\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3500.4363 - mae: 3500.4363 - val_loss: 3204.4009 - val_mae: 3204.4009\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3499.5525 - mae: 3499.5525 - val_loss: 3201.6023 - val_mae: 3201.6023\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3499.0884 - mae: 3499.0884 - val_loss: 3199.3152 - val_mae: 3199.3152\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3497.0420 - mae: 3497.0420 - val_loss: 3198.3262 - val_mae: 3198.3262\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3496.9526 - mae: 3496.9526 - val_loss: 3195.2239 - val_mae: 3195.2239\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3494.2476 - mae: 3494.2476 - val_loss: 3193.5276 - val_mae: 3193.5276\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3492.6619 - mae: 3492.6619 - val_loss: 3191.9763 - val_mae: 3191.9763\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3494.4302 - mae: 3494.4302 - val_loss: 3190.5981 - val_mae: 3190.5981\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3499.5476 - mae: 3499.5476 - val_loss: 3189.6492 - val_mae: 3189.6492\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3489.6113 - mae: 3489.6113 - val_loss: 3186.1990 - val_mae: 3186.1990\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3489.4980 - mae: 3489.4980 - val_loss: 3182.7947 - val_mae: 3182.7947\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3486.5242 - mae: 3486.5242 - val_loss: 3180.5845 - val_mae: 3180.5845\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3485.9067 - mae: 3485.9067 - val_loss: 3179.1147 - val_mae: 3179.1147\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3487.1304 - mae: 3487.1304 - val_loss: 3175.8855 - val_mae: 3175.8855\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3483.4333 - mae: 3483.4333 - val_loss: 3174.2517 - val_mae: 3174.2517\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3482.2856 - mae: 3482.2856 - val_loss: 3172.0349 - val_mae: 3172.0349\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3481.0896 - mae: 3481.0896 - val_loss: 3169.9097 - val_mae: 3169.9097\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3481.7021 - mae: 3481.7021 - val_loss: 3168.3423 - val_mae: 3168.3423\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3477.7532 - mae: 3477.7532 - val_loss: 3166.8042 - val_mae: 3166.8042\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3477.6370 - mae: 3477.6370 - val_loss: 3165.2778 - val_mae: 3165.2778\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3475.1636 - mae: 3475.1636 - val_loss: 3164.5830 - val_mae: 3164.5830\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3476.1902 - mae: 3476.1902 - val_loss: 3166.4524 - val_mae: 3166.4524\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.3499 - mae: 3474.3499 - val_loss: 3164.4873 - val_mae: 3164.4873\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.5261 - mae: 3473.5261 - val_loss: 3164.8899 - val_mae: 3164.8899\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.5505 - mae: 3474.5505 - val_loss: 3162.6184 - val_mae: 3162.6184\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.8113 - mae: 3473.8113 - val_loss: 3165.4819 - val_mae: 3165.4819\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.7573 - mae: 3473.7573 - val_loss: 3162.1064 - val_mae: 3162.1064\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.1458 - mae: 3473.1458 - val_loss: 3163.9541 - val_mae: 3163.9541\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.6060 - mae: 3472.6060 - val_loss: 3163.8672 - val_mae: 3163.8672\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.0464 - mae: 3473.0464 - val_loss: 3161.9863 - val_mae: 3161.9863\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.4614 - mae: 3472.4614 - val_loss: 3163.3777 - val_mae: 3163.3777\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.3301 - mae: 3474.3301 - val_loss: 3162.8838 - val_mae: 3162.8838\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.6287 - mae: 3473.6287 - val_loss: 3161.8845 - val_mae: 3161.8845\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.5249 - mae: 3472.5249 - val_loss: 3161.5859 - val_mae: 3161.5859\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.9167 - mae: 3474.9167 - val_loss: 3163.3594 - val_mae: 3163.3594\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.3635 - mae: 3472.3635 - val_loss: 3159.9192 - val_mae: 3159.9192\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.6228 - mae: 3472.6228 - val_loss: 3160.4246 - val_mae: 3160.4246\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3471.7224 - mae: 3471.7224 - val_loss: 3161.9775 - val_mae: 3161.9775\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3474.5171 - mae: 3474.5171 - val_loss: 3161.8950 - val_mae: 3161.8950\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.4294 - mae: 3473.4294 - val_loss: 3159.3303 - val_mae: 3159.3303\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.7971 - mae: 3472.7971 - val_loss: 3159.9604 - val_mae: 3159.9604\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3473.0500 - mae: 3473.0500 - val_loss: 3159.4380 - val_mae: 3159.4380\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3472.9028 - mae: 3472.9028 - val_loss: 3160.9514 - val_mae: 3160.9514\n"
     ]
    }
   ],
   "source": [
    "# Here, we also pass the test sets as `validation_data`, to get an imporesson, if and when the model overfits\n",
    "history_callback = insurance_model_4.fit(X_train_normal, y_train, epochs=500, validation_data = (X_test_normal, y_test), callbacks=callback_early_stopping, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e7d963-4e53-4a67-90d1-47b81ecf867d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history_callback.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edfb97c2-88fc-4035-8d80-b011593b36e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the model with early stopping callback\n",
    "pd.DataFrame(history_callback.history).plot()\n",
    "plt.ylim(3000, 14000)\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a25b4a0-56ca-4adb-9967-c38067e99c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the model trained for 200 total epochs loss curves\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylim(3000, 14000)\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a00c2-d11b-4818-85a3-ed98d3266df1",
   "metadata": {},
   "source": [
    "I seems we were pretty close to the minimum loss with 200 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0ba0d-4f66-477f-924f-e8899f83f6d6",
   "metadata": {},
   "source": [
    "### TensorBoard callback\n",
    "The TensorFlow documentation describes this the following way: \"TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\"\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d82fd0a-07c3-4667-877c-5149ba5a5f19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d005349f-df39-4327-bc02-6d52a4cb39f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a9043ad-6973-4667-ac4b-d5b07be78f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a549ea4d-34d5-4a5d-99e2-db1500911c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f846750-1908-4848-9c79-6547e211f6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build the model (3 layers, 100, 10, 1 units)\n",
    "insurance_model_6 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "insurance_model_6.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d5c8a31-2e79-4afc-9614-7ccc1e4f8fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "insurance_model_6_history = insurance_model_6.fit(X_train_normal, y_train, epochs=200, validation_data = (X_test_normal, y_test), callbacks=tensorboard_callback, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3555420-30fc-48ba-a2b1-ae65c94899ff",
   "metadata": {},
   "source": [
    "To start TensorBoard on the VSC JupyterHub, we need to bend over backwards a little bit. Thankfully, Katrin Muck from the VSC, wrote these cells of code to make it possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af25700d-dbbb-4691-a632-5d0e8fd1eb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard will be available at:\n",
      "https://jupyterhub.vsc.ac.at/user/trainee40/proxy/63040/\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "username = os.getenv('USER')\n",
    "if 'trainee' in username:\n",
    "    trainee_number = int(username.replace('trainee', ''))\n",
    "else:\n",
    "    trainee_number = hash(username) % 100\n",
    "TENSORBOARD_PORT = 63000 + trainee_number\n",
    "print('tensorboard will be available at:')\n",
    "URL = f'https://jupyterhub.vsc.ac.at/user/{username}/proxy/{TENSORBOARD_PORT}/'\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ba0adcb-ff28-4a68-b610-032ffed6832c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TENSORBOARD_PROXY_URL=https://jupyterhub.vsc.ac.at/user/trainee40/proxy/63040/\n"
     ]
    }
   ],
   "source": [
    "%set_env TENSORBOARD_PROXY_URL=$URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fe205b3-9c73-4ee6-b5cd-80bd5b8fbf71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2043b9e6c0ae7ea5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2043b9e6c0ae7ea5\");\n",
       "          const url = new URL(\"https://jupyterhub.vsc.ac.at/user/trainee40/proxy/63040/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit --bind_all --port $TENSORBOARD_PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efbcbc-fe64-4e9e-a727-14269d00745c",
   "metadata": {},
   "source": [
    "Ignore the error message. Instead open the following url in a new tab: https://jupyterhub.vsc.ac.at/user/traineexx/proxy/630xx/ with xx being your trainee ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327557b-053a-4152-aed5-cd2f9f5223f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
