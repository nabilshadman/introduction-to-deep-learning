{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b87fb3-1bfa-4eb0-bf60-e2be8704cf37",
   "metadata": {
    "id": "2WLKnUi6fI6B",
    "tags": []
   },
   "source": [
    "# Multi-class classification with a CNN\n",
    "\n",
    "To demonstrate the power of CNNs, we are going to download the [Fashion MNIST built-in](https://github.com/zalandoresearch/fashion-mnist) dataset directly via TensorFlow again. Just as in our previous notebook, you can import it using the [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6e0ec9-a0f9-4219-ae57-b0d2d7b28cbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zl50sxPTqpw4",
    "outputId": "a84d56e1-3caa-4fe3-da3d-daa957de8bb8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 14:13:19.481225: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-31 14:13:19.481319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-31 14:13:19.482135: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-31 14:13:19.488373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# The data has already been sorted into training and test sets for us\n",
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da49de-be07-4d16-86c3-bdeac75f4211",
   "metadata": {},
   "source": [
    "Check the shapes of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48cf683-913f-49b4-9205-f61c527d82f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN5-jr6arj19",
    "outputId": "875e43f8-6f45-4de7-a690-3e5f22dc9346",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of your data\n",
    "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09cb4b21-3277-4fa9-9160-8506ea0837ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNfIOUUEsJRt",
    "outputId": "eb29775a-9247-4b6f-f635-aa14a4152fa1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the shape of a single example\n",
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea5574-2bf8-4a75-ad3d-d206c278699c",
   "metadata": {
    "id": "r2wW0cEfsAve"
   },
   "source": [
    "You should have discovered 60,000 training examples each with shape (28, 28) and a label each as well as 10,000 test examples of shape (28, 28)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e7ca6-8bf7-423a-92bd-7cf5c3ce8354",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, plot some random images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090cc953-6b36-4312-937f-c6e8145ca686",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "RmC2VsWOscKP",
    "outputId": "90805579-22f4-410a-e140-8051a20665e8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7fd35fd49e10>, 39067)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random example\n",
    "random_image_number = np.random.randint(0, 59999)\n",
    "plt.imshow(train_data[random_image_number]), random_image_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed017b-c1c4-472a-921e-2821b79f86a6",
   "metadata": {
    "id": "sOqirdtfstdQ"
   },
   "source": [
    "What about its label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7969a36a-6353-4520-ab5e-af824de4c0da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzTDEpaYsxga",
    "outputId": "e436486f-eab2-4327-e8d0-13e6a6e78f99",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the random sample's label\n",
    "train_labels[random_image_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4053070-fb89-4eae-8108-ede82fe06f26",
   "metadata": {
    "id": "ZHdVBrCUs10A"
   },
   "source": [
    "The labels seem to be in numerical form. This is fine for a neural network, however, we would like some text labels.\n",
    "\n",
    "Let's create a list of the class names (you can find them on [the dataset's GitHub page](https://github.com/zalandoresearch/fashion-mnist#labels))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed2f2bc8-388a-48a8-b033-bc977e731dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGOi32T8s1ai",
    "outputId": "c585fda2-b5c2-4c34-b0dd-85fd5d24ecae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff1dd5-2d21-4a98-ab06-e34426298510",
   "metadata": {},
   "source": [
    "Determine the output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5271aa-a87f-41d2-a6c5-36419e63480d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGOi32T8s1ai",
    "outputId": "c585fda2-b5c2-4c34-b0dd-85fd5d24ecae",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many classes are there?\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8569e-6a3e-4a07-9966-117a1d2e78d5",
   "metadata": {},
   "source": [
    "Create a first model, which you think should be up to the classification job. Train for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f598ce-88b3-42c0-add0-7d94c94c0777",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUFHuzIpv30K",
    "outputId": "1cf10905-3f65-433d-cf34-fe0cc3f26158",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 14:13:22.486989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1022 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2025-03-31 14:13:23.205860: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-03-31 14:13:24.399773: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fd14f3b9f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-03-31 14:13:24.399848: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2025-03-31 14:13:24.405514: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743423204.515165 2634709 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 2ms/step - loss: 0.5067 - accuracy: 0.8469 - val_loss: 0.3242 - val_accuracy: 0.8837\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2978 - accuracy: 0.8904 - val_loss: 0.3142 - val_accuracy: 0.8830\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2635 - accuracy: 0.9027 - val_loss: 0.3030 - val_accuracy: 0.8907\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2395 - accuracy: 0.9112 - val_loss: 0.2789 - val_accuracy: 0.9007\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2239 - accuracy: 0.9152 - val_loss: 0.3080 - val_accuracy: 0.8894\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2075 - accuracy: 0.9227 - val_loss: 0.2764 - val_accuracy: 0.9049\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1954 - accuracy: 0.9273 - val_loss: 0.2995 - val_accuracy: 0.9044\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1807 - accuracy: 0.9319 - val_loss: 0.2761 - val_accuracy: 0.9122\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1733 - accuracy: 0.9357 - val_loss: 0.3064 - val_accuracy: 0.9086\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1611 - accuracy: 0.9407 - val_loss: 0.3120 - val_accuracy: 0.9055\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "CNN_model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=\"relu\", input_shape=(28,28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "CNN_model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 optimizer=tf.keras.optimizers.Adam(),\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_1 = CNN_model_1.fit(train_data,\n",
    "                                train_labels,\n",
    "                                epochs=10,\n",
    "                                validation_data=(test_data, test_labels)) # see how the model performs on the test set during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157079d-42a9-494a-9647-4e3a9e2dfb90",
   "metadata": {},
   "source": [
    "Have a look at the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af3c9db1-5991-4b7b-bd27-8568ed280128",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hzYWEgoVJ_p",
    "outputId": "6c30b8af-5f19-4c4c-c65e-68436f8d87d7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               401536    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421642 (1.61 MB)\n",
      "Trainable params: 421642 (1.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c2765e-b78b-43a6-8749-dd0cee7dc611",
   "metadata": {
    "id": "XRfkre59zSto"
   },
   "source": [
    "Does our model improve, if we pass it normalized data? First normalize the data and then refit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e633182-deb2-4a9b-bb2e-86b060d527cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGiweanwz82_",
    "outputId": "334ad24e-1c94-4973-8b4c-3e3c1eef7bc7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the min and max values of the training data\n",
    "train_data.min(), train_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70830f10-7796-40b7-9622-75dbe13c6524",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABRKp5U8voV_",
    "outputId": "5443c261-26ad-49f8-cf36-37d259224037",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide train and test images by the maximum value (normalize it)\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "# Check the min and max values of the training data\n",
    "train_data.min(), train_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d656976-f555-43d6-9e18-8cbc1005b106",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1QRy7y_K_87",
    "outputId": "340beb7f-f094-4225-b8a4-0422aab83c6c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4132 - accuracy: 0.8513 - val_loss: 0.3214 - val_accuracy: 0.8860\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2737 - accuracy: 0.8996 - val_loss: 0.3310 - val_accuracy: 0.8793\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2303 - accuracy: 0.9152 - val_loss: 0.2519 - val_accuracy: 0.9059\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2023 - accuracy: 0.9239 - val_loss: 0.2354 - val_accuracy: 0.9125\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1772 - accuracy: 0.9335 - val_loss: 0.2416 - val_accuracy: 0.9153\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1579 - accuracy: 0.9401 - val_loss: 0.2508 - val_accuracy: 0.9107\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1412 - accuracy: 0.9475 - val_loss: 0.2321 - val_accuracy: 0.9213\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1225 - accuracy: 0.9539 - val_loss: 0.2453 - val_accuracy: 0.9199\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1124 - accuracy: 0.9572 - val_loss: 0.2410 - val_accuracy: 0.9209\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0995 - accuracy: 0.9624 - val_loss: 0.2535 - val_accuracy: 0.9216\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "CNN_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=\"relu\", input_shape=(28,28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "CNN_model_2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 optimizer=tf.keras.optimizers.Adam(),\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "history_2 = CNN_model_2.fit(train_data,\n",
    "                                train_labels,\n",
    "                                epochs=10,\n",
    "                                validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39b3235-9c69-4397-8541-ca5bf19d204d",
   "metadata": {
    "id": "C_I2KNJiMWZ8"
   },
   "source": [
    "Indeed, there is an improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf1862-7f1f-40c0-8c05-311b177cd2ac",
   "metadata": {
    "id": "47g1wNk6iYTd"
   },
   "source": [
    "Now, create at least two more variations of the CNN above. I.e. try different hyperparameters, or leave entire layers away (e.g. drop out layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a95c566-87e3-4532-98b3-2a6dd9e32883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4855 - accuracy: 0.8231 - val_loss: 0.3559 - val_accuracy: 0.8741\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3226 - accuracy: 0.8828 - val_loss: 0.3640 - val_accuracy: 0.8658\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2805 - accuracy: 0.8968 - val_loss: 0.2929 - val_accuracy: 0.8924\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2529 - accuracy: 0.9068 - val_loss: 0.2576 - val_accuracy: 0.9074\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2316 - accuracy: 0.9152 - val_loss: 0.2592 - val_accuracy: 0.9061\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "CNN_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=\"relu\", input_shape=(28,28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (2,2), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "CNN_model_3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 optimizer=tf.keras.optimizers.Adam(),\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_3 = CNN_model_3.fit(train_data,\n",
    "                                train_labels,\n",
    "                                epochs=5,\n",
    "                                validation_data=(test_data, test_labels)) # see how the model performs on the test set during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c27ac86-7b2f-4199-9f96-c2fae9609c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 7, 7, 128)         32896     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 3, 3, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63242 (247.04 KB)\n",
      "Trainable params: 63242 (247.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adae0af2-f6d3-4d7e-8d66-d313f76df16b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.5503 - accuracy: 0.7978 - val_loss: 0.3697 - val_accuracy: 0.8693\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3692 - accuracy: 0.8652 - val_loss: 0.3445 - val_accuracy: 0.8757\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3216 - accuracy: 0.8817 - val_loss: 0.2909 - val_accuracy: 0.8919\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2951 - accuracy: 0.8916 - val_loss: 0.2648 - val_accuracy: 0.9034\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2767 - accuracy: 0.8982 - val_loss: 0.2612 - val_accuracy: 0.9048\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2623 - accuracy: 0.9028 - val_loss: 0.2510 - val_accuracy: 0.9098\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2472 - accuracy: 0.9072 - val_loss: 0.2383 - val_accuracy: 0.9106\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2395 - accuracy: 0.9107 - val_loss: 0.2457 - val_accuracy: 0.9086\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2331 - accuracy: 0.9129 - val_loss: 0.2311 - val_accuracy: 0.9144\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2247 - accuracy: 0.9161 - val_loss: 0.2371 - val_accuracy: 0.9125\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2194 - accuracy: 0.9184 - val_loss: 0.2229 - val_accuracy: 0.9193\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2100 - accuracy: 0.9212 - val_loss: 0.2251 - val_accuracy: 0.9169\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2067 - accuracy: 0.9220 - val_loss: 0.2159 - val_accuracy: 0.9210\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2021 - accuracy: 0.9243 - val_loss: 0.2236 - val_accuracy: 0.9183\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1983 - accuracy: 0.9255 - val_loss: 0.2116 - val_accuracy: 0.9234\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1935 - accuracy: 0.9265 - val_loss: 0.2124 - val_accuracy: 0.9232\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1881 - accuracy: 0.9291 - val_loss: 0.2129 - val_accuracy: 0.9234\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1853 - accuracy: 0.9292 - val_loss: 0.2085 - val_accuracy: 0.9255\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1817 - accuracy: 0.9318 - val_loss: 0.2196 - val_accuracy: 0.9200\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1787 - accuracy: 0.9336 - val_loss: 0.2132 - val_accuracy: 0.9229\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "CNN_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=\"relu\", input_shape=(28,28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "CNN_model_4.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 optimizer=tf.keras.optimizers.Adam(),\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_4 = CNN_model_4.fit(train_data,\n",
    "                                train_labels,\n",
    "                                epochs=20,\n",
    "                                validation_data=(test_data, test_labels)) # see how the model performs on the test set during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0deef-849c-44e8-ba1f-8fc639b7b037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
